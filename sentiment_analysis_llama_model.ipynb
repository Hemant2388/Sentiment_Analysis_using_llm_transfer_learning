{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 93282,
          "databundleVersionId": 11098970,
          "sourceType": "competition"
        },
        {
          "sourceId": 104449,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 68809,
          "modelId": 91102
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "21F1001345",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemant2388/Sentiment_Analysis_using_llm_transfer_learning/blob/main/sentiment_analysis_llama_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "63zoZs_5FYqt"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "multi_lingual_sentiment_analysis_path = kagglehub.competition_download('multi-lingual-sentiment-analysis')\n",
        "metaresearch_llama_3_1_transformers_8b_instruct_2_path = kagglehub.model_download('metaresearch/llama-3.1/Transformers/8b-instruct/2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "YZuMW0BEFYq1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "model_path = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:46:09.272803Z",
          "iopub.execute_input": "2025-02-17T12:46:09.273056Z",
          "iopub.status.idle": "2025-02-17T12:46:10.548083Z",
          "shell.execute_reply.started": "2025-02-17T12:46:09.273034Z",
          "shell.execute_reply": "2025-02-17T12:46:10.547338Z"
        },
        "id": "_XxjKVDjFYq3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install bitsandbytes evaluate datasets"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:38:09.023839Z",
          "iopub.execute_input": "2025-02-17T11:38:09.024314Z",
          "iopub.status.idle": "2025-02-17T11:38:12.645629Z",
          "shell.execute_reply.started": "2025-02-17T11:38:09.024289Z",
          "shell.execute_reply": "2025-02-17T11:38:12.644757Z"
        },
        "id": "JRLgk3ayFYq5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from pprint import pprint\n",
        "import math\n",
        "import wandb\n",
        "\n",
        "#hf\n",
        "import datasets\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import LlamaConfig, LlamaForCausalLM,LlamaForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:46:15.136356Z",
          "iopub.execute_input": "2025-02-17T12:46:15.136764Z",
          "iopub.status.idle": "2025-02-17T12:46:41.899099Z",
          "shell.execute_reply.started": "2025-02-17T12:46:15.136738Z",
          "shell.execute_reply": "2025-02-17T12:46:41.898313Z"
        },
        "id": "6BxGDLzxFYq7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/kaggle/input/multi-lingual-sentiment-analysis/train.csv')\n",
        "test_df = pd.read_csv('/kaggle/input/multi-lingual-sentiment-analysis/test.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:46:43.735077Z",
          "iopub.execute_input": "2025-02-17T12:46:43.735792Z",
          "iopub.status.idle": "2025-02-17T12:46:43.791625Z",
          "shell.execute_reply.started": "2025-02-17T12:46:43.735763Z",
          "shell.execute_reply": "2025-02-17T12:46:43.790775Z"
        },
        "id": "bFQVGaHuFYq9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:23:37.360214Z",
          "iopub.execute_input": "2025-02-17T12:23:37.360516Z",
          "iopub.status.idle": "2025-02-17T12:23:40.103287Z",
          "shell.execute_reply.started": "2025-02-17T12:23:37.360489Z",
          "shell.execute_reply": "2025-02-17T12:23:40.102622Z"
        },
        "id": "nABaAp9HFYq-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\"Negative\": 0, \"Positive\": 1}\n",
        "train_df[\"label\"] = train_df[\"label\"].map(label_map)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:31.954502Z",
          "iopub.execute_input": "2025-02-17T11:56:31.954824Z",
          "iopub.status.idle": "2025-02-17T11:56:31.960961Z",
          "shell.execute_reply.started": "2025-02-17T11:56:31.9548Z",
          "shell.execute_reply": "2025-02-17T11:56:31.959785Z"
        },
        "id": "KcJrBVbtFYrA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:32.81579Z",
          "iopub.execute_input": "2025-02-17T11:56:32.81612Z",
          "iopub.status.idle": "2025-02-17T11:56:32.819734Z",
          "shell.execute_reply.started": "2025-02-17T11:56:32.816063Z",
          "shell.execute_reply": "2025-02-17T11:56:32.818964Z"
        },
        "id": "gQcMdRdiFYrC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:33.554312Z",
          "iopub.execute_input": "2025-02-17T11:56:33.554637Z",
          "iopub.status.idle": "2025-02-17T11:56:33.573059Z",
          "shell.execute_reply.started": "2025-02-17T11:56:33.554611Z",
          "shell.execute_reply": "2025-02-17T11:56:33.572428Z"
        },
        "id": "dI90WneXFYrF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:34.438224Z",
          "iopub.execute_input": "2025-02-17T11:56:34.43853Z",
          "iopub.status.idle": "2025-02-17T11:56:34.442484Z",
          "shell.execute_reply.started": "2025-02-17T11:56:34.438509Z",
          "shell.execute_reply": "2025-02-17T11:56:34.441509Z"
        },
        "id": "lPmx7L4QFYrG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path,model_max_length=1024)\n",
        "# set pad token id\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:35.037621Z",
          "iopub.execute_input": "2025-02-17T11:56:35.03794Z",
          "iopub.status.idle": "2025-02-17T11:56:35.525996Z",
          "shell.execute_reply.started": "2025-02-17T11:56:35.037914Z",
          "shell.execute_reply": "2025-02-17T11:56:35.524965Z"
        },
        "id": "FYskVN9lFYrG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "    example = tokenizer(example['sentence'],padding=False,truncation=True)\n",
        "    return example"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:35.759974Z",
          "iopub.execute_input": "2025-02-17T11:56:35.760274Z",
          "iopub.status.idle": "2025-02-17T11:56:35.764293Z",
          "shell.execute_reply.started": "2025-02-17T11:56:35.760252Z",
          "shell.execute_reply": "2025-02-17T11:56:35.763401Z"
        },
        "id": "xWrZhhnHFYrH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:36.51364Z",
          "iopub.execute_input": "2025-02-17T11:56:36.513938Z",
          "iopub.status.idle": "2025-02-17T11:56:36.519256Z",
          "shell.execute_reply.started": "2025-02-17T11:56:36.513915Z",
          "shell.execute_reply": "2025-02-17T11:56:36.518555Z"
        },
        "id": "YHH4AMR-FYrL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds = ds.map(tokenize,batched=True,num_proc=12, remove_columns=['ID', 'sentence', 'language'])\n",
        "print(tokenized_ds)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:37.27656Z",
          "iopub.execute_input": "2025-02-17T11:56:37.276868Z",
          "iopub.status.idle": "2025-02-17T11:56:39.643949Z",
          "shell.execute_reply.started": "2025-02-17T11:56:37.276845Z",
          "shell.execute_reply": "2025-02-17T11:56:39.642922Z"
        },
        "id": "qczgFffnFYrM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ds_split = tokenized_ds['train'].train_test_split(test_size=0.1,seed=42)\n",
        "print(ds_split)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:39.64548Z",
          "iopub.execute_input": "2025-02-17T11:56:39.645787Z",
          "iopub.status.idle": "2025-02-17T11:56:39.656108Z",
          "shell.execute_reply.started": "2025-02-17T11:56:39.645763Z",
          "shell.execute_reply": "2025-02-17T11:56:39.655122Z"
        },
        "id": "KumkI3MFFYrM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " data_collator = DataCollatorWithPadding(tokenizer,padding=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:39.657543Z",
          "iopub.execute_input": "2025-02-17T11:56:39.657765Z",
          "iopub.status.idle": "2025-02-17T11:56:39.665266Z",
          "shell.execute_reply.started": "2025-02-17T11:56:39.657746Z",
          "shell.execute_reply": "2025-02-17T11:56:39.664378Z"
        },
        "id": "NlsjQYSWFYrM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",  # Best for LLaMA models\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Can also use bfloat16 if supported\n",
        "    bnb_4bit_use_double_quant=True,  # Further reduces memory usage\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:39.666365Z",
          "iopub.execute_input": "2025-02-17T11:56:39.666662Z",
          "iopub.status.idle": "2025-02-17T11:56:39.680805Z",
          "shell.execute_reply.started": "2025-02-17T11:56:39.666634Z",
          "shell.execute_reply": "2025-02-17T11:56:39.680052Z"
        },
        "id": "2AJqWbSdFYrO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     model_path,\n",
        "#     num_labels=2,\n",
        "#     pad_token_id=tokenizer.eos_token_id,\n",
        "#     quantization_config=bnb_config,\n",
        "#     device_map=\"auto\"\n",
        "# )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:42.521824Z",
          "iopub.execute_input": "2025-02-17T11:56:42.522148Z",
          "iopub.status.idle": "2025-02-17T11:56:42.525804Z",
          "shell.execute_reply.started": "2025-02-17T11:56:42.522122Z",
          "shell.execute_reply": "2025-02-17T11:56:42.524751Z"
        },
        "id": "19TlgPIVFYrO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, TaskType, LoraModel\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias='none'\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:43.324302Z",
          "iopub.execute_input": "2025-02-17T11:56:43.324631Z",
          "iopub.status.idle": "2025-02-17T11:56:43.32885Z",
          "shell.execute_reply.started": "2025-02-17T11:56:43.324602Z",
          "shell.execute_reply": "2025-02-17T11:56:43.328162Z"
        },
        "id": "FlId1O_1FYrO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from peft import LoraConfig, get_peft_model, TaskType\n",
        "# model = get_peft_model(model, lora_config)\n",
        "# model.print_trainable_parameters()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:44.315042Z",
          "iopub.execute_input": "2025-02-17T11:56:44.315425Z",
          "iopub.status.idle": "2025-02-17T11:56:44.420837Z",
          "shell.execute_reply.started": "2025-02-17T11:56:44.315398Z",
          "shell.execute_reply": "2025-02-17T11:56:44.41996Z"
        },
        "id": "8rrDKFsVFYrP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "  # for name,param in model.named_parameters():\n",
        "  #     if name != \"score.weight\":\n",
        "  #        param.requires_grad = False\n",
        "  #     print(name,param.requires_grad)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:45.299455Z",
          "iopub.execute_input": "2025-02-17T11:56:45.299777Z",
          "iopub.status.idle": "2025-02-17T11:56:45.303264Z",
          "shell.execute_reply.started": "2025-02-17T11:56:45.299749Z",
          "shell.execute_reply": "2025-02-17T11:56:45.302355Z"
        },
        "id": "HP6Bk9HTFYrP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  num_parameters = 0\n",
        "#  for param in model.parameters():\n",
        "#      if param.requires_grad:\n",
        "#          num_parameters += param.numel()\n",
        "# print(f'Number of Parameters:{num_parameters}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:46.200328Z",
          "iopub.execute_input": "2025-02-17T11:56:46.200611Z",
          "iopub.status.idle": "2025-02-17T11:56:46.204163Z",
          "shell.execute_reply.started": "2025-02-17T11:56:46.200589Z",
          "shell.execute_reply": "2025-02-17T11:56:46.203264Z"
        },
        "id": "KsCFFaQVFYrP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:46.935223Z",
          "iopub.execute_input": "2025-02-17T11:56:46.935561Z",
          "iopub.status.idle": "2025-02-17T11:56:47.487356Z",
          "shell.execute_reply.started": "2025-02-17T11:56:46.935538Z",
          "shell.execute_reply": "2025-02-17T11:56:47.486434Z"
        },
        "id": "RzcqvQ-3FYrQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_bf16_supported())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:48.653208Z",
          "iopub.execute_input": "2025-02-17T11:56:48.653551Z",
          "iopub.status.idle": "2025-02-17T11:56:48.658395Z",
          "shell.execute_reply.started": "2025-02-17T11:56:48.653522Z",
          "shell.execute_reply": "2025-02-17T11:56:48.657523Z"
        },
        "id": "v9UvfLt-FYrQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#model.gradient_checkpointing_enable()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:50.060301Z",
          "iopub.execute_input": "2025-02-17T11:56:50.060586Z",
          "iopub.status.idle": "2025-02-17T11:56:50.063946Z",
          "shell.execute_reply.started": "2025-02-17T11:56:50.060565Z",
          "shell.execute_reply": "2025-02-17T11:56:50.063067Z"
        },
        "id": "M5_5Yt69FYrQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./llama8_multilingual_ft',\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    num_train_epochs=3,  # Train for more epochs since data is limited\n",
        "    per_device_train_batch_size=2,  # Lowered for memory reasons (P100 GPU)\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=8,  # Effective batch size is 2 * 8 = 16\n",
        "    bf16=False,  # P100 doesn't support BF16\n",
        "    fp16=False,  # Mixed precision training for memory efficiency\n",
        "    gradient_checkpointing=True,  # Save memory on large models\n",
        "    optim=\"adamw_torch\",  # More efficient optimizer with torch backend\n",
        "    learning_rate=0.1,  # Typically better for LoRA fine-tuning\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,  # Save less frequently to avoid storage issues\n",
        "    report_to='none',\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_num_workers=2,  # Reduce to avoid Kaggle kernel crashes\n",
        "    ddp_find_unused_parameters=False,  # Single GPU, this is safe\n",
        "    max_grad_norm=1.0,\n",
        "    warmup_steps=10,  # Helps stabilize early training\n",
        "    lr_scheduler_type=\"cosine\",  # Often works well with fine-tuning LLaMA\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:51.050765Z",
          "iopub.execute_input": "2025-02-17T11:56:51.051072Z",
          "iopub.status.idle": "2025-02-17T11:56:51.081805Z",
          "shell.execute_reply.started": "2025-02-17T11:56:51.05105Z",
          "shell.execute_reply": "2025-02-17T11:56:51.081053Z"
        },
        "id": "4bV80cRzFYrR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=ds_split[\"train\"],\n",
        "#     eval_dataset=ds_split[\"test\"],\n",
        "#     data_collator = data_collator,\n",
        "#     compute_metrics = compute_metrics\n",
        "# )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:53.865888Z",
          "iopub.execute_input": "2025-02-17T11:56:53.86627Z",
          "iopub.status.idle": "2025-02-17T11:56:53.885718Z",
          "shell.execute_reply.started": "2025-02-17T11:56:53.866242Z",
          "shell.execute_reply": "2025-02-17T11:56:53.885065Z"
        },
        "id": "IDBJkTMpFYrR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#results = trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:56:54.741547Z",
          "iopub.execute_input": "2025-02-17T11:56:54.741836Z",
          "iopub.status.idle": "2025-02-17T11:56:54.745529Z",
          "shell.execute_reply.started": "2025-02-17T11:56:54.741814Z",
          "shell.execute_reply": "2025-02-17T11:56:54.744464Z"
        },
        "id": "LwdJ80m6FYrR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#simple model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T11:57:06.701503Z",
          "iopub.execute_input": "2025-02-17T11:57:06.701798Z",
          "iopub.status.idle": "2025-02-17T11:57:06.705462Z",
          "shell.execute_reply.started": "2025-02-17T11:57:06.701774Z",
          "shell.execute_reply": "2025-02-17T11:57:06.704383Z"
        },
        "id": "oG5lrB7IFYrS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "print(f'Vocab size: {tokenizer.vocab_size}')\n",
        "print(f'Context length: {tokenizer.model_max_length}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:46:56.456727Z",
          "iopub.execute_input": "2025-02-17T12:46:56.457003Z",
          "iopub.status.idle": "2025-02-17T12:46:57.118526Z",
          "shell.execute_reply.started": "2025-02-17T12:46:56.456982Z",
          "shell.execute_reply": "2025-02-17T12:46:57.1177Z"
        },
        "id": "IIGFTC9KFYrS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token=tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:46:57.699429Z",
          "iopub.execute_input": "2025-02-17T12:46:57.699684Z",
          "iopub.status.idle": "2025-02-17T12:46:57.703238Z",
          "shell.execute_reply.started": "2025-02-17T12:46:57.699662Z",
          "shell.execute_reply": "2025-02-17T12:46:57.702394Z"
        },
        "id": "vyz7_SnNFYrT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:47:02.981759Z",
          "iopub.execute_input": "2025-02-17T12:47:02.982039Z",
          "iopub.status.idle": "2025-02-17T12:47:02.985777Z",
          "shell.execute_reply.started": "2025-02-17T12:47:02.982017Z",
          "shell.execute_reply": "2025-02-17T12:47:02.984836Z"
        },
        "id": "7mfEGvqeFYrT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    num_labels = 2\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:48:59.096523Z",
          "iopub.execute_input": "2025-02-17T12:48:59.096816Z",
          "iopub.status.idle": "2025-02-17T12:50:27.102818Z",
          "shell.execute_reply.started": "2025-02-17T12:48:59.096795Z",
          "shell.execute_reply": "2025-02-17T12:50:27.101893Z"
        },
        "id": "Tzu9UUcdFYrT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:50:29.885663Z",
          "iopub.execute_input": "2025-02-17T12:50:29.886068Z",
          "iopub.status.idle": "2025-02-17T12:50:29.893121Z",
          "shell.execute_reply.started": "2025-02-17T12:50:29.886033Z",
          "shell.execute_reply": "2025-02-17T12:50:29.892261Z"
        },
        "id": "5gDSIPQvFYrU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ps0xucCJFYrU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for idx, row in test_df.iterrows():\n",
        "    prompt = prompt = f\"\"\"\n",
        "Classify the sentiment of the provided sentence as either **\"Positive\"** or **\"Negative\"** based on its overall tone and context. The sentiment reflects the speaker's satisfaction, opinion, or emotional response.\n",
        "\n",
        "Language: {row['language']}\n",
        "Sentence: \"{row['sentence']}\"\n",
        "\n",
        "Answer with only \"Positive\" or \"Negative\":\n",
        "\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=2)\n",
        "\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    result_cleaned = result.strip().split()[-1].capitalize()# Handles cases like \"Positive\\nExplanation\"\n",
        "\n",
        "    if result_cleaned not in [\"Positive\", \"Negative\"]:\n",
        "        result_cleaned = \"Positive\"  # Fallback or handle it differently\n",
        "\n",
        "    if result_cleaned == \"Positive\":\n",
        "        predictions.append(\"Positive\")\n",
        "    elif result_cleaned == \"Negative\":\n",
        "        predictions.append(\"Negative\")\n",
        "    else:\n",
        "        predictions.append(\"Positive\")  # Fallback if it's neither"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:52:09.075865Z",
          "iopub.execute_input": "2025-02-17T12:52:09.07621Z",
          "iopub.status.idle": "2025-02-17T12:52:42.092185Z",
          "shell.execute_reply.started": "2025-02-17T12:52:09.076179Z",
          "shell.execute_reply": "2025-02-17T12:52:42.09153Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "a092lmW6FYrU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.DataFrame(predictions)).value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:55:24.030502Z",
          "iopub.execute_input": "2025-02-17T12:55:24.030808Z",
          "iopub.status.idle": "2025-02-17T12:55:24.040794Z",
          "shell.execute_reply.started": "2025-02-17T12:55:24.030784Z",
          "shell.execute_reply": "2025-02-17T12:55:24.039853Z"
        },
        "id": "xn-8UAMNFYrV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame(columns = ['ID', 'label'])\n",
        "submission['ID'] = [i for i in range(1, len(predictions)+1)]\n",
        "submission['label'] = predictions\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-17T12:55:27.419767Z",
          "iopub.execute_input": "2025-02-17T12:55:27.420036Z",
          "iopub.status.idle": "2025-02-17T12:55:27.438075Z",
          "shell.execute_reply.started": "2025-02-17T12:55:27.420016Z",
          "shell.execute_reply": "2025-02-17T12:55:27.437206Z"
        },
        "id": "KOswtdzVFYrV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "HiYUUjQxFYrb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "OWXHqA8CFYrb"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}